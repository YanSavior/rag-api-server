from sentence_transformers import SentenceTransformer, CrossEncoder
import torch
import numpy as np
from typing import List, Dict, Tuple
import os
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

class SimpleVectorizer:
    """ç®€å•çš„TF-IDFå‘é‡åŒ–å™¨ï¼Œç”¨äºç¦»çº¿æ¨¡å¼"""
    
    def __init__(self):
        """åˆå§‹åŒ–TF-IDFå‘é‡åŒ–å™¨"""
        self.vectorizer = TfidfVectorizer(
            max_features=1000,
            stop_words=None,
            ngram_range=(1, 2)
        )
        self.is_fitted = False
        print("ä½¿ç”¨TF-IDFå‘é‡åŒ–å™¨ï¼ˆç¦»çº¿æ¨¡å¼ï¼‰")
    
    def fit_transform(self, texts: List[str]) -> np.ndarray:
        """æ‹Ÿåˆå¹¶è½¬æ¢æ–‡æœ¬"""
        embeddings = self.vectorizer.fit_transform(texts)
        self.is_fitted = True
        return embeddings.toarray()
    
    def transform(self, texts: List[str]) -> np.ndarray:
        """è½¬æ¢æ–°æ–‡æœ¬"""
        if not self.is_fitted:
            raise ValueError("å‘é‡åŒ–å™¨å°šæœªæ‹Ÿåˆï¼Œè¯·å…ˆè°ƒç”¨fit_transform")
        embeddings = self.vectorizer.transform(texts)
        return embeddings.toarray()
    
    def encode_texts(self, texts: List[str], batch_size: int = 32) -> np.ndarray:
        """æ‰¹é‡ç¼–ç æ–‡æœ¬ä¸ºå‘é‡"""
        if not self.is_fitted:
            return self.fit_transform(texts)
        return self.transform(texts)
    
    def encode_single(self, text: str) -> np.ndarray:
        """ç¼–ç å•ä¸ªæ–‡æœ¬"""
        return self.transform([text])[0]

class BGEVectorizer:
    """BGEæ¨¡å‹å‘é‡åŒ–å™¨ï¼Œä½¿ç”¨Sentence Transformersæ¥å£"""
    
    def __init__(self, model_name="BAAI/bge-small-zh-v1.5", force_bge=False):
        """
        åˆå§‹åŒ–BGEå‘é‡åŒ–å™¨
        
        Args:
            model_name: BGEæ¨¡å‹åç§°
            force_bge: æ˜¯å¦å¼ºåˆ¶ä½¿ç”¨BGEæ¨¡å‹ï¼ˆå¦‚æœå¤±è´¥ä¼šæŠ›å‡ºå¼‚å¸¸ï¼‰
        """
        try:
            print(f"ğŸ”„ æ­£åœ¨åŠ è½½BGEæ¨¡å‹: {model_name}")
            self.model = SentenceTransformer(model_name)
            print(f"âœ… BGEæ¨¡å‹åŠ è½½å®Œæˆ: {model_name}")
            self.use_simple = False
        except Exception as e:
            print(f"âŒ æ— æ³•åŠ è½½BGEæ¨¡å‹: {e}")
            if force_bge:
                raise Exception(f"å¼ºåˆ¶BGEæ¨¡å¼å¤±è´¥: {e}")
            print("ğŸ”„ åˆ‡æ¢åˆ°TF-IDFå‘é‡åŒ–å™¨ï¼ˆç¦»çº¿æ¨¡å¼ï¼‰")
            self.model = SimpleVectorizer()
            self.use_simple = True
        
        # æ£€æŸ¥GPUå¯ç”¨æ€§
        if not self.use_simple:
            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
            self.model = self.model.to(self.device)
            print(f"ğŸ–¥ï¸ ä½¿ç”¨è®¾å¤‡: {self.device}")
    
    def get_model_info(self):
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        if self.use_simple:
            return {
                "type": "TF-IDF",
                "mode": "offline",
                "description": "ä½¿ç”¨TF-IDFå‘é‡åŒ–å™¨ï¼Œæ— éœ€ç½‘ç»œè¿æ¥"
            }
        else:
            return {
                "type": "BGE",
                "mode": "online",
                "description": f"ä½¿ç”¨BGEæ¨¡å‹: {self.model.model_name if hasattr(self.model, 'model_name') else 'Unknown'}"
            }
    
    def encode_texts(self, texts: List[str], batch_size: int = 32) -> np.ndarray:
        """
        æ‰¹é‡ç¼–ç æ–‡æœ¬ä¸ºå‘é‡
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            batch_size: æ‰¹å¤„ç†å¤§å°
            
        Returns:
            å‘é‡æ•°ç»„
        """
        if self.use_simple:
            return self.model.encode_texts(texts, batch_size)
        
        embeddings = self.model.encode(
            texts,
            batch_size=batch_size,
            show_progress_bar=True,
            convert_to_tensor=True,
            normalize_embeddings=True
        )
        return embeddings.cpu().numpy()
    
    def encode_single(self, text: str) -> np.ndarray:
        """
        ç¼–ç å•ä¸ªæ–‡æœ¬
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            
        Returns:
            å‘é‡
        """
        if self.use_simple:
            return self.model.encode_single(text)
        
        embedding = self.model.encode(
            [text],
            convert_to_tensor=True,
            normalize_embeddings=True
        )
        return embedding[0].cpu().numpy()

class SimpleReranker:
    """ç®€å•çš„é‡æ’å™¨ï¼Œä½¿ç”¨TF-IDFç›¸ä¼¼åº¦"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç®€å•é‡æ’å™¨"""
        self.vectorizer = TfidfVectorizer(
            max_features=1000,
            stop_words=None,
            ngram_range=(1, 2)
        )
        print("ä½¿ç”¨TF-IDFé‡æ’å™¨ï¼ˆç¦»çº¿æ¨¡å¼ï¼‰")
    
    def rerank(self, query: str, documents: List[str], top_k: int = 5) -> List[Dict]:
        """
        å¯¹æ–‡æ¡£è¿›è¡Œé‡æ’
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            documents: å€™é€‰æ–‡æ¡£åˆ—è¡¨
            top_k: è¿”å›å‰kä¸ªç»“æœ
            
        Returns:
            é‡æ’åçš„ç»“æœåˆ—è¡¨
        """
        # å‡†å¤‡æ‰€æœ‰æ–‡æœ¬
        all_texts = [query] + documents
        
        # å‘é‡åŒ–
        embeddings = self.vectorizer.fit_transform(all_texts)
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        query_embedding = embeddings[0:1]
        doc_embeddings = embeddings[1:]
        
        similarities = cosine_similarity(query_embedding, doc_embeddings)[0]
        
        # åˆ›å»ºç»“æœåˆ—è¡¨
        results = []
        for i, (doc, score) in enumerate(zip(documents, similarities)):
            results.append({
                'document': doc,
                'score': float(score),
                'index': i
            })
        
        # æŒ‰åˆ†æ•°æ’åº
        results.sort(key=lambda x: x['score'], reverse=True)
        return results[:top_k]

class CrossEncoderReranker:
    """Cross-Encoderé‡æ’å™¨"""
    
    def __init__(self, model_name="BAAI/bge-reranker-v2-m3"):
        """åˆå§‹åŒ–Cross-Encoderé‡æ’å™¨"""
        try:
            print(f"ğŸ”„ æ­£åœ¨åŠ è½½Cross-Encoderæ¨¡å‹: {model_name}")
            self.model = CrossEncoder(model_name)
            print(f"âœ… Cross-Encoderæ¨¡å‹åŠ è½½å®Œæˆ: {model_name}")
            self.use_simple = False
        except Exception as e:
            print(f"âŒ æ— æ³•åŠ è½½Cross-Encoderæ¨¡å‹: {e}")
            print("ğŸ”„ åˆ‡æ¢åˆ°TF-IDFé‡æ’å™¨ï¼ˆç¦»çº¿æ¨¡å¼ï¼‰")
            self.model = SimpleReranker()
            self.use_simple = True
    
    def get_model_info(self):
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        if self.use_simple:
            return {
                "type": "TF-IDF",
                "mode": "offline",
                "description": "ä½¿ç”¨TF-IDFé‡æ’å™¨ï¼Œæ— éœ€ç½‘ç»œè¿æ¥"
            }
        else:
            return {
                "type": "Cross-Encoder",
                "mode": "online",
                "description": f"ä½¿ç”¨Cross-Encoderæ¨¡å‹: {self.model.model_name if hasattr(self.model, 'model_name') else 'Unknown'}"
            }
    
    def rerank(self, query: str, documents: List[str], top_k: int = 5) -> List[Dict]:
        """
        å¯¹æ–‡æ¡£è¿›è¡Œé‡æ’
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            documents: å€™é€‰æ–‡æ¡£åˆ—è¡¨
            top_k: è¿”å›å‰kä¸ªç»“æœ
            
        Returns:
            é‡æ’åçš„ç»“æœåˆ—è¡¨
        """
        if self.use_simple:
            return self.model.rerank(query, documents, top_k)
        
        # å‡†å¤‡æŸ¥è¯¢-æ–‡æ¡£å¯¹
        query_doc_pairs = [(query, doc) for doc in documents]
        
        # è®¡ç®—åˆ†æ•°
        scores = self.model.predict(query_doc_pairs)
        
        # åˆ›å»ºç»“æœåˆ—è¡¨
        results = []
        for i, (doc, score) in enumerate(zip(documents, scores)):
            results.append({
                'document': doc,
                'score': float(score),
                'index': i
            })
        
        # æŒ‰åˆ†æ•°æ’åº
        results.sort(key=lambda x: x['score'], reverse=True)
        return results[:top_k]

class AdvancedRAGVectorizer:
    """é«˜çº§RAGå‘é‡åŒ–å™¨ï¼Œé›†æˆBi-Encoderå’ŒCross-Encoder"""
    
    def __init__(self, 
                 bi_encoder_model="BAAI/bge-small-zh-v1.5",
                 cross_encoder_model="BAAI/bge-reranker-v2-m3"):
        """
        åˆå§‹åŒ–é«˜çº§RAGå‘é‡åŒ–å™¨
        
        Args:
            bi_encoder_model: Bi-Encoderæ¨¡å‹åç§°
            cross_encoder_model: Cross-Encoderæ¨¡å‹åç§°
        """
        self.bi_encoder = BGEVectorizer(bi_encoder_model)
        self.cross_encoder = CrossEncoderReranker(cross_encoder_model)
        print("é«˜çº§RAGå‘é‡åŒ–å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def retrieve_and_rerank(self, 
                           query: str, 
                           documents: List[str], 
                           top_k_retrieve: int = 20, 
                           top_k_final: int = 5) -> List[Dict]:
        """
        æ£€ç´¢-é‡æ’æµç¨‹
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            documents: æ–‡æ¡£åˆ—è¡¨
            top_k_retrieve: ç²—æ£€ç´¢å€™é€‰æ•°é‡
            top_k_final: æœ€ç»ˆç»“æœæ•°é‡
            
        Returns:
            æœ€ç»ˆç»“æœåˆ—è¡¨
        """
        print(f"å¼€å§‹æ£€ç´¢-é‡æ’æµç¨‹...")
        print(f"æŸ¥è¯¢: {query}")
        print(f"æ–‡æ¡£æ€»æ•°: {len(documents)}")
        
        # ç¬¬ä¸€æ­¥ï¼šBi-Encoderç²—æ£€ç´¢
        print("ç¬¬ä¸€æ­¥ï¼šBi-Encoderç²—æ£€ç´¢...")
        candidate_docs = self._bi_encoder_retrieve(query, documents, top_k_retrieve)
        
        # ç¬¬äºŒæ­¥ï¼šCross-Encoderç²¾æ’
        print("ç¬¬äºŒæ­¥ï¼šCross-Encoderç²¾æ’...")
        final_results = self._cross_encoder_rerank(query, candidate_docs, top_k_final)
        
        print(f"æ£€ç´¢-é‡æ’å®Œæˆï¼Œè¿”å› {len(final_results)} ä¸ªç»“æœ")
        return final_results
    
    def _bi_encoder_retrieve(self, query: str, documents: List[str], top_k: int) -> List[Dict]:
        """Bi-Encoderç²—æ£€ç´¢"""
        
        # ç¼–ç æŸ¥è¯¢å’Œæ–‡æ¡£
        query_embedding = self.bi_encoder.model.encode(query, convert_to_tensor=True)
        doc_embeddings = self.bi_encoder.model.encode(documents, convert_to_tensor=True)
        
        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        similarities = torch.cosine_similarity(query_embedding.unsqueeze(0), doc_embeddings)
        
        # è·å–top_kå€™é€‰
        top_indices = torch.argsort(similarities, descending=True)[:top_k]
        
        candidates = []
        for idx in top_indices:
            candidates.append({
                'document': documents[idx],
                'bi_encoder_score': similarities[idx].item(),
                'index': idx.item()
            })
        
        print(f"ç²—æ£€ç´¢å®Œæˆï¼Œè·å¾— {len(candidates)} ä¸ªå€™é€‰æ–‡æ¡£")
        return candidates
    
    def _cross_encoder_rerank(self, query: str, candidates: List[Dict], top_k: int) -> List[Dict]:
        """Cross-Encoderç²¾æ’"""
        
        # æå–æ–‡æ¡£å†…å®¹
        documents = [candidate['document'] for candidate in candidates]
        
        # ä½¿ç”¨Cross-Encoderé‡æ’
        reranked_results = self.cross_encoder.rerank(query, documents, top_k)
        
        # åˆå¹¶ç»“æœ
        final_results = []
        for i, reranked in enumerate(reranked_results):
            # æ‰¾åˆ°å¯¹åº”çš„åŸå§‹å€™é€‰
            original_candidate = candidates[reranked['index']]
            
            final_results.append({
                'document': reranked['document'],
                'bi_encoder_score': original_candidate['bi_encoder_score'],
                'cross_encoder_score': reranked['score'],
                'index': reranked['index']
            })
        
        print(f"ç²¾æ’å®Œæˆï¼Œè¿”å› {len(final_results)} ä¸ªæœ€ç»ˆç»“æœ")
        return final_results 